<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>源码 on My New Hugo Site</title>
    <link>https://example.org/tags/%E6%BA%90%E7%A0%81/</link>
    <description>Recent content in 源码 on My New Hugo Site</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Apr 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.org/tags/%E6%BA%90%E7%A0%81/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(二)etcd记录-Put&amp;Watch的联系</title>
      <link>https://example.org/posts/etcd_2/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/etcd_2/</guid>
      <description>etcd支持watch功能，即监听一个或者一部分范围内的key，当这些key有变化时，收到通知。 那么仔细看一下put和watch都分别干了什么，这两个操作又是如何关联在一起的。&#xA;这里暂时先忽略掉raft复制、选举等过程，只仔细看下put是如何与watch交互的部分：&#xA;Put操作 整个put操作的流水线涉及了EtcdServer,raftNode,node,rawNode四个对象之间的通信，其中大量使用了管道通信，先按照我的理解大概画出通信流程帮助记忆，因为整个流程还是比较长的。 接下来跟着源代码走一遍这个流程：&#xA;从grpc server注册处可以看到，put的入口是kvServer的Put方法，该方法中其实就是调用了etcdServer.Put进行业务处理的,&#xA;func (s *EtcdServer) Put(ctx context.Context, r *pb.PutRequest) (*pb.PutResponse, error) { ctx = context.WithValue(ctx, traceutil.StartTimeKey, time.Now()) resp, err := s.raftRequest(ctx, pb.InternalRaftRequest{Put: r}) // InternalRaftRequest是可以通过raft发送的所有请求的集合，这里把put的请求放进去，为raft的一致性同步过程做准备。 if err != nil { return nil, err } return resp.(*pb.PutResponse), nil } raftRequest方法展开后可以到达processInternalRaftRequestOnce方法，该方法就是实际处理一次raft操作的地方。&#xA;func (s *EtcdServer) processInternalRaftRequestOnce(ctx context.Context, r pb.InternalRaftRequest) (*applyResult, error) { ... ch := s.w.Register(id) // 用id注册一个管道，当用相同id调用wait.Trigger方法时，响应结果会从管道中流出。id是生成器(idutil.Generator)生成的请求id cctx, cancel := context.WithTimeout(ctx, s.Cfg.ReqTimeout()) defer cancel() start := time.</description>
    </item>
    <item>
      <title>(一)etcd记录-兼容http方式的grpc</title>
      <link>https://example.org/posts/etcd_1/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/etcd_1/</guid>
      <description>etcd是一个开源的可分布式部署的k-v存储系统，一般用来做配置共享、服务发现等需求。 其在k8s中起到了很关键的作用，主要功能为：存储k8s要持久化的数据以及保证分布式等需求集群的数据一致性。 作为一个35k星的开源项目很有必要学习一下其结构设计和代码设计(etcd相关源代码基于3.5.0-alpha.0实验版本,且只浏览v3版本接口) 这不是一个入门的使用说明，是对etcd中部分有趣的设计的分享：&#xA;grpc &amp;amp; http etcd的客户端和服务端使用了一元grpc(kv查询等)和双向流grpc(watch)通信方式，grpc的原理和基本使用就不再说了，记录下看到三个可以一次编码同时服务grpc和http流量的方法：&#xA;grpc实现http的Handler 以serverClients函数为例，看下客户端的服务启动过程：&#xA;gs = v3rpc.Server(s, tlscfg, gopts...) v3electionpb.RegisterElectionServer(gs, servElection) v3lockpb.RegisterLockServer(gs, servLock) if sctx.serviceRegister != nil { sctx.serviceRegister(gs) } handler = grpcHandlerFunc(gs, handler) 可以看到这里封装了grpcHandlerFunc将grpc的handler也转换为http.Handler,通过判断http协议版本以及请求头中grpc标志性的Content-Type=application/grpc来决定哪一部分流量走http，哪一部分走grpc。&#xA;func grpcHandlerFunc(grpcServer *grpc.Server, otherHandler http.Handler) http.Handler { if otherHandler == nil { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { grpcServer.ServeHTTP(w, r) }) } return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if r.ProtoMajor == 2 &amp;amp;&amp;amp; strings.Contains(r.Header.Get(&amp;#34;Content-Type&amp;#34;), &amp;#34;application/grpc&amp;#34;) { grpcServer.ServeHTTP(w, r) // grpc.</description>
    </item>
    <item>
      <title>golang官方包源码阅读记录 sync.Map</title>
      <link>https://example.org/posts/sync-map/</link>
      <pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/sync-map/</guid>
      <description>功能介绍 源码阅读 结构 方法 Add()&#xA;Wait()&#xA;state()</description>
    </item>
    <item>
      <title>golang官方包源码阅读记录 sync.Cond和sync.Once</title>
      <link>https://example.org/posts/sync-cond-once/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/sync-cond-once/</guid>
      <description>功能介绍 sync.Cond是一个条件锁。使用场景就是在你一个groutine已经获得锁后进行条件判断，如果不满足条件，直接等待通知，而不需要循环等下一次判断。 sync.Once可以保证一段代码只执行一次。 源码阅读 sync.Cond条件锁使用了Locker接口实现自己锁定的功能，一般可以直接使用Mutex或者RWMutex作为锁。&#xA;使用场景比如：一个队列已经被写满了，写入也没有任何判断。这时如果直接再次写入，就会抢到锁后无法写入，然后其他读协程也抢不到锁，读写都无法进行死锁了。 解决这种问题， 每次抢到锁后尝试写入时先判断是否满了，满了的话则解锁进入循环，不断尝试；或者就是利用Cond解锁后等待通知。 相当于一个是自己盯着什么时候好，一个是等别人来告诉你已经好了。&#xA;sync.Once通过使用一个整形记录使用次数，保证了要保护的资源在整个程序运行期间只会执行一次。当然该结构也不能复制，否则就起不到保护作用了&#xA;sync.Cond结构 type Cond struct { noCopy noCopy // go vet检查 L Locker // 实现了Locker的锁 notify notifyList // sema中关于通知的实现， 下面另说 checker copyChecker // 自己实现的复制检查 } sync.Cond方法 Cond提供了Wait(),Single(),Broadcast()三个方法。功能以及实现逻辑很简单。&#xA;Wait()功能为加锁后判断条件不满足阻塞等待通知&#xA;Single()功能为随机通知一个groutine Broadcast()功能为通知全部groutine 三个方法如下&#xA;type copyChecker uintptr func (c *copyChecker) check() { // 一个实例Cond，第一次调用的时候值是0，将checker的地址作为值赋值给checker，以后每次判断 当前地址是否和自身的值相同。如果有复制，则肯定要新开辟一段地址，那么checker地址肯定变，但是他的值却还是之前的地址，判断时就会不相同。 if uintptr(*c) != uintptr(unsafe.Pointer(c)) &amp;amp;&amp;amp; !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) &amp;amp;&amp;amp; uintptr(*c) != uintptr(unsafe.Pointer(c)) { panic(&amp;#34;sync.Cond is copied&amp;#34;) } } // 用法模板 // c.</description>
    </item>
    <item>
      <title>golang官方包源码阅读记录 sync.RWMutex</title>
      <link>https://example.org/posts/sync-rwmutex/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/sync-rwmutex/</guid>
      <description>功能介绍 sync.Mutex是golang官方实现的读写互斥锁。目的是为了在读写分离的场景下提高锁的效率。该锁不限制并发读，但是对于并发读写以及并发写作限制 源码阅读 读写锁复用了Mutex的功能用于对写并发进行阻塞。对于读写分离方面，没有很复杂的逻辑，利用计数器以及groutine唤醒机制进行读写锁分离。&#xA;结构 type RWMutex struct { w Mutex // 如果有写并发参与，则复用Mutex的功能进行阻塞 writerSem uint32 // 写角色信号量 readerSem uint32 // 读角色信号量 readerCount int32 // 当前有多少读并发 readerWait int32 // 开始进行写操作是有多少读操作未完成。需要写操作等待其完成 } 方法 RWMutex提供了Lock(),Unlock(),RLock(),RUnlock()四个方法来实现读写分离锁。&#xA;Lock()&#xA;func (rw *RWMutex) Lock() { if race.Enabled { _ = rw.w.state race.Disable() } // Lock函数是写锁，因此首先使用Mutex的lock功能限制其他写的groutine rw.w.Lock() // 然后判断当前是否还有读操作，将readerCount先变为负数。证明现在有写操作开始进行了 r := atomic.AddInt32(&amp;amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // 如果r!=0也就是rw.readerCount大于0。那么证明当前的确还有读操作没进行完。 // 同时将readerWait置为当前readerCount的值，以便读锁解锁时可以正确-1 // 然后将进入睡眠等待读锁全部释放后将其唤醒 if r != 0 &amp;amp;&amp;amp; atomic.AddInt32(&amp;amp;rw.readerWait, r) !</description>
    </item>
    <item>
      <title>golang官方包源码阅读记录 sync.WaitGroup</title>
      <link>https://example.org/posts/sync-waitgroup/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/sync-waitgroup/</guid>
      <description>功能介绍 sync.WaitGroup是官方给出用于保证并发一致性的工具。他可以阻塞等待多个groutine任务完成后 再继续往下执行。 源码阅读 类似互斥锁那样，WaitGroup内部也运用了位运算以及groutine睡眠唤醒机制。来保证以最小代价正确计数以及成功唤醒阻塞等待的groutine。&#xA;结构 type WaitGroup struct { noCopy noCopy // 64-bit value: high 32 bits are counter, low 32 bits are waiter count. // 64-bit atomic operations require 64-bit alignment, but 32-bit // compilers do not ensure it. So we allocate 12 bytes and then use // the aligned 8 bytes in them as state, and the other 4 as storage // for the sema. // 我们需要使用64位数据表示计数器：即高32位表示当前已添加任务的数量， // 后32位表示使用wait等待的数量。 // 因为这里需要对这个64位数字进行原子操作，32位编译器没法保证对齐。 // 所以干脆申请96位数据表示整个状态 // 其中有整齐的64位用来表示state进行计数，后面32位存储信号量 state1 [3]uint32 } 方法 WaitGroup提供了Wait(),Add(),Done()三个方法，其中Done方法就是调用Add(-1),没有什么特殊的地方</description>
    </item>
    <item>
      <title>github.com/melbahja/got 号称比wget和curl更快的下载工具</title>
      <link>https://example.org/posts/github-got/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/github-got/</guid>
      <description>刷社区发现这个号称比wget更快的下载器，拉下来学习一下设计思想：&#xA;设计思路 首先向目标发起发起head请求，获取文件大小以及判断accept-ranges是否等于bytes，如果不符合分段请求的条件，或者拿不到文件大小，则直接返回。 根据目标文件大小以及并发数量计算每一个并发chunk需要下载的内容，以及有多少个chunk 根据chunk的数量进行不同的操作：如果是没有chunk，即head请求不符合预期则直接全量下载；如果是多个chunk，则将各自负责的那一部分按照顺序下载到不同的临时文件中，所有都下载完之后，将这写文件中的内容再按照顺序合并并输出到目标文件。 </description>
    </item>
    <item>
      <title>golang官方包源码阅读记录 sync.Mutex</title>
      <link>https://example.org/posts/sync-mutex/</link>
      <pubDate>Wed, 15 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/sync-mutex/</guid>
      <description>功能介绍 sync.Mutex是golang官方实现的互斥锁。这是一个公平锁，尽最大可能保证所有groutine有同等概率得到锁,不会出现某个groutine一直拿不到锁的情况。 这个是如何保证的呢？mutex分为两种状态，正常态和饥饿态。饥饿状态就是为了解决某些groutine在排队队列中一直竞争不到锁而设计出来的，一旦mutex变为饥饿态。释放锁的时候就会直接交给队列的第一个而不会让大家去竞争。从而保证了不会有尾部延时情况出现。 源码阅读 互斥锁中依然有大量的位运算以及很巧妙的设计,对着代码做一下注释：&#xA;结构 // mutex是一个互斥的锁 // mutex的0值是没有上锁的状态，即mutex只要定义了，不比初始化就是就可用的。 // 一个mutex从第一次开始使用就不能被赋值，所以用函数传递mutex是不推荐的，必须要这样操作的话也只能传递指针。 type Mutex struct { state int32 sema uint32 } 可以看到Mutex下只有两个32位字段state和sema，也就是说8个字节就能表示一个互斥锁。&#xA;其中state是表示整个锁的状态，这个属性可以被多个groutine访问，通过atmoic的原子操作避免竞争问题。&#xA;需要注意的是这个int32中从低到高前三个bit为都是状态为。第一位表示是否锁定，第二位表示是否是唤醒状态，第三位表示是否是饥饿状态，再往高的位表示的是当前正在等待排队期望获取锁的groutine数量。&#xA;sema则是信号量，其机制为：acquire时如果sema大于0，那么减一返回，否则休眠等待。release将sema加一，然后唤醒等待队列的一个goroutine。&#xA;方法 Mutex互斥锁提供了Lock()和Unlock()方法。&#xA;Lock()&#xA;// Lock 锁定m. // 如果lock已经被使用了，则调用方会被阻塞直到mutex可用 func (m *Mutex) Lock() { // 类似上一篇的sync.Pool有慢获取一样，这里也分为快加锁和慢加锁 // 加锁的实质其实就是取得能修改m.state的权利 // 快速路： cas操作可以将m.state由0变为1 if atomic.CompareAndSwapInt32(&amp;amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // 如果无法获取锁，那么就走慢路径。这里单独抽出来作为一个独立函数是为了让快速路可以内联提升点性能。 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 // 等待锁的时间，判断变身为饥饿锁的依据 starving := false // 当前groutine内表示是否是饥饿态，注意区分state中的饥饿态标识位 awoke := false // 当前groutine内表示是否是唤醒态，注意区分state中的唤醒态标识位 iter := 0 // 次数，自旋用到的，超过4次就不允许自旋了 old := m.</description>
    </item>
    <item>
      <title>golang官方包源码阅读记录 sync.Pool</title>
      <link>https://example.org/posts/sync-pool/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://example.org/posts/sync-pool/</guid>
      <description>功能介绍 golang的sync包是用于进行并发控制，其中sync.Pool是比较常用到的一个结构。其目的很简单：缓存已分配但暂时未使用的对象以便以后可以复用，避免大量创建临时对象，减轻GC压力。需要注意的是不要认为存入的对象和取出的对象之间有任何关系，池中的数据会在GC时被清空。如果pool中为空，则会返回自定义的New函数返回的对象。下面是摘抄的一小段官方注释：&#xA;A Pool is a set of temporary objects that may be individually saved and retrieved. Any item stored in the Pool may be removed automatically at any time without notification. If the Pool holds the only reference when this happens, the item might be deallocated. 使用示例可参考json包的Marshal函数。&#xA;func Marshal(v interface{}) ([]byte, error) { e := newEncodeState() // 从池中去除一个对象 ...... encodeStatePool.Put(e) // 将从池中取出来的对象重新放入池中 return buf, nil } func newEncodeState() *encodeState { if v := encodeStatePool.</description>
    </item>
  </channel>
</rss>
